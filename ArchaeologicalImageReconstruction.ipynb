{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "VXlbdS67xfBZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "num_samples = 1000\n",
        "image_size = 64\n",
        "num_epochs = 50\n",
        "batch_size = 64\n",
        "learning_rate = 0.0002"
      ],
      "metadata": {
        "id": "1tZGM6Yhx5AP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic dataset\n",
        "clean_images = torch.rand(num_samples, 1, image_size, image_size)\n",
        "noise = torch.randn_like(clean_images) * 0.5\n",
        "damaged_images = clean_images + noise\n"
      ],
      "metadata": {
        "id": "7IUjrx8mx95_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoader\n",
        "dataset = TensorDataset(damaged_images, clean_images)\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "Y1xbITbEyEgW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator model\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            # Define architecture\n",
        "            nn.Conv2d(1, 32, 4, 2, 1),   # input size: 1x64x64, output size: 32x32x32\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 64, 4, 2, 1),  # input size: 32x32x32, output size: 64x16x16\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), # input size: 64x16x16, output size: 128x8x8\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 1, 4, 2, 1),  # input size: 128x8x8, output size: 1x4x4\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "i0T896uUyM74"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator model\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            # Define architecture\n",
        "            nn.Conv2d(2, 32, 4, 2, 1),   # input size: 2x64x64, output size: 32x32x32\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(32, 64, 4, 2, 1),  # input size: 32x32x32, output size: 64x16x16\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), # input size: 64x16x16, output size: 128x8x8\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(128, 1, 4, 2, 1),  # input size: 128x8x8, output size: 1x4x4\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "ewApPLLXyXqX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize generator and discriminator\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "5ZWV6FnSyaHG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "criterion = nn.BCELoss()\n"
      ],
      "metadata": {
        "id": "GRtp9UWkymce"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizers\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))"
      ],
      "metadata": {
        "id": "AEJcFk60ysoN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (damaged_images, clean_images) in enumerate(data_loader):\n",
        "        # Adversarial ground truths\n",
        "        valid = torch.ones(clean_images.size(0), 1, 4, 4).to(device)\n",
        "        fake = torch.zeros(clean_images.size(0), 1, 4, 4).to(device)\n",
        "        # Configure input\n",
        "        damaged_images = damaged_images.to(device)\n",
        "        clean_images = clean_images.to(device)\n",
        "         # Train Discriminator\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "W-QTqtY2yy8o"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a batch of images\n",
        "generated_images = generator(damaged_images)\n",
        "\n",
        "# Resize generated_images to match the spatial dimensions of damaged_images\n",
        "generated_images_resized = nn.functional.interpolate(generated_images, size=(64, 64), mode='bilinear', align_corners=False)\n",
        "\n",
        "# Measure discriminator's ability to classify fake images\n",
        "fake_loss = criterion(discriminator(torch.cat((damaged_images, generated_images_resized), dim=1)), fake)\n",
        ""
      ],
      "metadata": {
        "id": "iT30LpVKznVj"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (damaged_images, clean_images) in enumerate(data_loader):\n",
        "        # Adversarial ground truths\n",
        "        valid = torch.ones(clean_images.size(0), 1, 4, 4).to(device)\n",
        "        fake = torch.zeros(clean_images.size(0), 1, 4, 4).to(device)\n",
        "\n",
        "        # Configure input\n",
        "        damaged_images = damaged_images.to(device)\n",
        "        clean_images = clean_images.to(device)\n",
        "\n",
        "        # Train Discriminator\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TAsNQOZp0xH6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure both tensors have the same batch size\n",
        "batch_size = damaged_images.size(0)\n",
        "generated_images = generated_images[:batch_size]\n",
        "\n",
        "# Resize generated_images to match the spatial dimensions of damaged_images\n",
        "generated_images_resized = torch.nn.functional.interpolate(generated_images, size=(damaged_images.size(2), damaged_images.size(3)), mode='bilinear', align_corners=False)\n",
        "\n",
        "# Print out sizes for debugging\n",
        "print(\"Damaged Images Size:\", damaged_images.size())\n",
        "print(\"Generated Images Resized Size:\", generated_images_resized.size())\n",
        "\n",
        "# Measure discriminator's ability to classify fake images\n",
        "fake_loss = criterion(discriminator(torch.cat((damaged_images, generated_images_resized), dim=1)), fake)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtajSOgi1XIK",
        "outputId": "aea161a5-1ee0-4dfe-ebaf-fb8a11d5d846"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Damaged Images Size: torch.Size([40, 1, 64, 64])\n",
            "Generated Images Resized Size: torch.Size([40, 1, 64, 64])\n"
          ]
        }
      ]
    }
  ]
}